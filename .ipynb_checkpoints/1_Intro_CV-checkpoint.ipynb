{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vk3azjsizGss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image paths ....\n"
     ]
    }
   ],
   "source": [
    "intro_images_path='./Images/Intro_images/'\n",
    "edge_images_path='../'#../Images/Edge_images/'\n",
    "seg_images_path='../'#../Images/Seg_images/'\n",
    "feature_images_path='../'#../Images/Feature_images/'\n",
    "output_path='./Images/Outputs/'\n",
    "print('Image paths ....')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2OoXoPRIckk"
   },
   "source": [
    "# COMPUTER VISION I\n",
    "\n",
    "**Master in Artificial Intelligence, USC, UDC, UVigo**\n",
    "\n",
    "Academic year 2022/23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./Logotipo_Solo.png\" width=200/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDE and Package Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda\n",
    "\n",
    "Anaconda® Distribution is a Python/R data science distribution that contains conda, a package and environment manager, which helps users manage a collection of over 7,500+ open-source packages available to them.\n",
    "\n",
    "Anaconda is free and easy to install:\n",
    "- *https://docs.anaconda.com/anaconda/*\n",
    "- *https://docs.anaconda.com/_downloads/9ee215ff15fde24bf01791d719084950/Anaconda-Starter-Guide.pdf*\n",
    "\n",
    "With conda, you can create, export, list, remove, and update environments that have different versions of Python and/or packages installed in them. Switching or moving between environments is called activating the environment. \n",
    "Create an environment with the last compatible and avialble (platform dependent) python and OpenCV packages.\n",
    "\n",
    "Within any environment you can install, update ore removing packages. Before any of this actions are performed a compatibility check is done.\n",
    "\n",
    "**Tested environment:**\n",
    "***python 3.7, opencv 3.4.2***\n",
    "\n",
    "\n",
    "\n",
    "### PyCharm vs Spyder vs Jupyter Notebook\n",
    "\n",
    "- PyCharm and Spyder are both cross-platform IDEs (Integrated Development Environments) featuring many helpful and intelligent features such as code completion, syntax highlighting and style analysis. However:\n",
    "   - Spyder is a lightweight IDE specifically designed for scientific Python development\n",
    "\n",
    "   - PyCharm is more resource-intensive and much more powerful for programming. Consider PyCharm if you plan to build large, complex applications where you’ll have a need for features like version control, code snippets, safe refactoring and an integrated project browser. \n",
    "   \n",
    "- Jupyter is an IPython notebook that allows you to combine code, text and visualizations in one document. Consider Jupyter if you want to easily present and share data visualizations along with code and text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## GOOGLE COLAB:\n",
    "\n",
    "If you have used Jupyter notebook previously, you would quickly learn to use Google Colab. Colab is a free Jupyter notebook environment that runs entirely in the cloud. Most importantly, it does not require a setup and the notebooks that you create can be simultaneously edited by your team members. Colab supports many popular machine learning libraries which can be easily loaded in your notebook:\n",
    "\n",
    "     https://www.tutorialspoint.com/google_colab/google_colab_quick_guide.htm\n",
    "\n",
    "\n",
    "### What Colab Offers You? \n",
    "\n",
    "Write and execute code in Python\n",
    "\n",
    "- Document your code that supports mathematical equations\n",
    "- Create/Upload/Share notebooks\n",
    "- Import/Save notebooks from/to Google Drive\n",
    "- Import/Publish notebooks from GitHub\n",
    "- Import external datasets e.g. from Kaggle\n",
    "- Integrate PyTorch, TensorFlow, Keras, OpenCV\n",
    "- Free Cloud service with free GPU\n",
    "\n",
    "\n",
    "*Google Colab: https://colab.research.google.com/*\n",
    " \n",
    "*Google Colab with GitHub: https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBfL4kgFIsyP"
   },
   "source": [
    "# Digital images\n",
    "\n",
    "- Reading,displaying and saving images\n",
    "- Color spaces\n",
    "- Drawing and writting on images\n",
    "- Image sampling and quantization\n",
    "- Image histograms\n",
    "\n",
    "\n",
    "\n",
    "http://szeliski.org/Book/\n",
    "\n",
    "https://docs.opencv.org/4.3.0/dc/d2e/tutorial_py_image_display.html\n",
    "\n",
    "https://docs.opencv.org/3.4.2/dc/d2e/tutorial_py_image_display.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlTMB9pGJ5E5"
   },
   "source": [
    "### Exercise Getting Started with OpenCV\n",
    "\n",
    "Repeat the first exercises on this page:\n",
    "\n",
    "https://docs.opencv.org/4.3.0/dc/d2e/tutorial_py_image_display.html\n",
    "\n",
    "https://docs.opencv.org/3.4.2/dc/d2e/tutorial_py_image_display.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvd1-2PTKmAe"
   },
   "source": [
    "**Read an image**\n",
    "\n",
    "Use the function cv2.imread() to read an image. The image should be in the working directory or a full path of image should be given.\n",
    "Second argument is a flag which specifies the way image should be read:\n",
    "\n",
    "cv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "\n",
    "cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode.\n",
    "\n",
    "cv2.IMREAD_UNCHANGED : Loads image as such including alpha channel.\n",
    "\n",
    "Instead of these three flags, you can simply pass integers 1, 0 or -1 respectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zNr9I7MLLfvQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread(intro_images_path +'pazo.jpg',0)\n",
    "\n",
    "if img is None:\n",
    "  sys.exit('Failing at loading image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLgq7l2JK3rO"
   },
   "source": [
    "**Display an image using Opencv**\n",
    "\n",
    "Use the function cv2.imshow() to display an image in a window. The window automatically fits to the image size.\n",
    "\n",
    "First argument is a window name which is a string. Second argument is our image. You can create as many windows as you wish, but with different window names.\n",
    "\n",
    "cv2.waitKey() is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke. It can also be set to detect specific key strokes.\n",
    "\n",
    "If you are using a 64-bit machine, you will have to modify k = cv2.waitKey(0) line as follows : k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "cv2.destroyAllWindows() simply destroys all the windows we created. If you want to destroy any specific window, use the function cv2.destroyWindow() where you pass the exact window name as the argument.\n",
    "\n",
    "**Save an image**\n",
    "\n",
    "Use the function cv2.imwrite() to save an image. First argument is the file name, second argument is the image you want to save.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 2427,
     "status": "ok",
     "timestamp": 1610376864101,
     "user": {
      "displayName": "Xosé M. Pardo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDK9_rXK-VnAMPThurPFbjh3ermYOtwwiKrrsh-w=s64",
      "userId": "09967233662722245852"
     },
     "user_tz": -60
    },
    "id": "9EBH8bFmPLT6",
    "outputId": "aaecc73b-4128-48b2-8eed-9209c444a7c8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "#Load an color image in grayscale\n",
    "img = cv2.imread(intro_images_path+'pazo.jpg')\n",
    "    \n",
    "cv2.imshow('image',img)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "k = cv2.waitKey(0) & 0xFF\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()\n",
    "elif k == ord('s'): # wait for 's' key to save and exit\n",
    "    cv2.imwrite(output_path+'pazo_gray.jpg',img)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "np.set_printoptions(edgeitems=25)\n",
    "print(\"Data type = {}\\n\".format(img.dtype))\n",
    "print(\"Object type = {}\\n\".format(type(img)))\n",
    "print('Image size:{}\\n'.format(img.shape))\n",
    "print('Channel G of the {} upper left window:\\n'.format('20x20'))\n",
    "print(img[0:20,0:20,1])\n",
    "print('\\nOrigin (0,0), first index row, second index column:')\n",
    "print('Element (1,0): {}'.format(img[1,0,1]))\n",
    "print('Element (0,1): {}\\n'.format(img[0,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display an image using Matplotlib**\n",
    "\n",
    "Matplotlib is a plotting library for Python which gives you wide variety of plotting methods. Here, you will learn how to display image with Matplotlib. You can zoom images, save it, etc., using Matplotlib. There is a slight difference in pixel ordering in OpenCV and Matplotlib. OpenCV follows BGR order, while matplotlib likely follows RGB order. So when you display an image loaded in OpenCV using pylab functions, you may need to convert it into RGB mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 2427,
     "status": "ok",
     "timestamp": 1610376864101,
     "user": {
      "displayName": "Xosé M. Pardo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDK9_rXK-VnAMPThurPFbjh3ermYOtwwiKrrsh-w=s64",
      "userId": "09967233662722245852"
     },
     "user_tz": -60
    },
    "id": "9EBH8bFmPLT6",
    "outputId": "aaecc73b-4128-48b2-8eed-9209c444a7c8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 \n",
    "\n",
    "#Load an color image in grayscale\n",
    "img = cv2.imread(intro_images_path+'pazo.jpg')\n",
    "    \n",
    "b,g,r = cv2.split(img)       # get b,g,r\n",
    "img = cv2.merge([r,g,b])     # switch it to rgb\n",
    "#img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #alternatively...\n",
    "\n",
    "img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "print(\"Data type = {}\\n\".format(img.dtype))\n",
    "print(\"Object type = {}\\n\".format(type(img)))\n",
    "print(\"Image size = {}\\n\".format(img.shape))\n",
    "print(' {} upper left window in gray-levle:\\n'.format('20x20'))\n",
    "print(img[0:20,0:20])\n",
    "print('\\nOrigin (0,0), first index row, second index column:')\n",
    "print('Element (1,0): {}'.format(img[1,0]))\n",
    "print('Element (0,1): {}\\n'.format(img[0,1]))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()\n",
    "retval=cv2.imwrite(output_path+'img_gray.png',img) \n",
    "\n",
    "if retval is True:\n",
    "    print('saved image!')\n",
    "else:\n",
    "    print('Error saving image!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3RP3rWMdkyd"
   },
   "source": [
    "### Exercise Changing Color‐space\n",
    "\n",
    "https://docs.opencv.org/4.3.0/df/d9d/tutorial_py_colorspaces.html\n",
    "\n",
    "https://docs.opencv.org/3.4.2/df/d9d/tutorial_py_colorspaces.html\n",
    "\n",
    "There are more than 150 color-space conversion methods available in OpenCV. But we will look into only two which are most widely used ones, BGR Gray and BGR HSV.\n",
    "\n",
    "For color conversion, we use the function cv2.cvtColor(input_image, flag) where flag determines the type of conversion.\n",
    "\n",
    "For BGR Gray conversion we use the flags cv2.COLOR_BGR2GRAY. Similarly for BGR HSV, we use the flag cv2.COLOR_BGR2HSV. \n",
    "\n",
    "To get other flags, just run following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1568799312362,
     "user": {
      "displayName": "Xosé M. Pardo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBS6i6mUhTeZja15gGzcKuHj5HDMgJBVGR1sh1UAQ=s64",
      "userId": "09967233662722245852"
     },
     "user_tz": -120
    },
    "id": "42A8ZNZFN72c",
    "outputId": "1bb74711-52db-4893-8e53-6d9d05394695"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print(flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Opening\n",
    "\n",
    "In OpenCV, a video can be read either by using the feed from a camera connected to a computer or by reading a video file. The first step towards reading a video file is to create a VideoCapture object. Its argument can be either the device index or the name of the video file to be read.\n",
    "\n",
    "In most cases, only one camera is connected to the system. So, all we do is pass ‘0’ and OpenCV uses the only camera attached to the computer. When more than one camera is connected to the computer, we can select the second camera by passing ‘1’, the third camera by passing ‘2’ and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('./Videos/example_01.mp4')\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Video opening failed!\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "  # Capturamos frame-a-frame\n",
    "  ret, frame = cap.read()\n",
    "    \n",
    "  if ret == True:\n",
    "    cv2.imshow(\"Video\", frame)    \n",
    "    # We wait 25 ms before next frame is displayed\n",
    "    # Quits if key 'q'is pressed\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "  # brake the loop\n",
    "  else: \n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Live video\n",
    "cap = cv2.VideoCapture(0)\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Video feeding failed!\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "  # frame-to-frame capture\n",
    "  ret, frame = cap.read()\n",
    "    \n",
    "  if ret == True:\n",
    "    cv2.imshow(\"Video\", frame)    \n",
    "    #Argument equals to 1 to acommodate to camera frame-rate\n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    \n",
    "  # Rompemos o lazo\n",
    "  else: \n",
    "    break\n",
    "    \n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing a video**\n",
    "\n",
    "To save a video, wee need to create a VideoWriter object. First, we should specify the output file name with its format (eg: output.avi). Then, we should specify the FourCC code and the number of frames per second (FPS). Lastly, the frame size should be passed.\n",
    "FourCC is a 4-byte code used to specify the video codec. The list of available codes can be found at fourcc.org. There are many FOURCC codes available.\n",
    "\n",
    "Only a few of the FourCC codes listed above will work based on the availability of the codecs on your system. Sometimes, even when the specific codec is available, OpenCV may not be able to use it. MJPG is a safe choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Live video\n",
    "cap = cv2.VideoCapture(0)\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Video feeding failed!\")\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "out = cv2.VideoWriter(output_path+'outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "  # frame-to-frame capture\n",
    "  ret, frame = cap.read()\n",
    "  out.write(frame)\n",
    "\n",
    "  if ret == True:\n",
    "    cv2.imshow(\"Video\", frame)    \n",
    "    #Argument equals to 1 to acommodate to camera frame-rate\n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drawing and writing on images\n",
    "\n",
    "Functions to write text and draw different geometric shapes with OpenCV: cv.line(), cv.circle() , cv.rectangle(), cv.ellipse(), cv.putText() etc.\n",
    "\n",
    "\n",
    "In all the above functions, you will see some common arguments as given below:\n",
    "\n",
    "**img**: The image where you want to draw the shapes.\n",
    "\n",
    "**color**: Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.\n",
    "\n",
    "**thickness**: Thickness of the line or circle etc. If -1 is passed for closed figures like circles, it will fill the shape. default thickness = 1\n",
    "\n",
    "**lineType**: Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv.LINE_AA gives anti-aliased line which looks great for curves.\n",
    "\n",
    "Learn more in https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 \n",
    "\n",
    "image = cv2.imread(intro_images_path+'overexposed.jpg')\n",
    "\n",
    "# Draw two circles (one full),one rectange,\n",
    "cv2.circle(image, center=(120, 110), radius=90, color=(0, 0, 255), thickness=2)\n",
    "cv2.circle(image, (350, 160), 10, (255, 0, 0), -1)\n",
    "\n",
    "cv2.rectangle(image, (370, 100), (465, 300), (0, 0, 255),2)\n",
    "\n",
    "#escribimos un texto na imaxe\n",
    "cv2.putText(image, \"Text!\",org=(30,30),fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=(0, 255,0), thickness=2)\n",
    "\n",
    "# visualizamos\n",
    "plt.imshow(image)\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image sampling and quantization\n",
    "\n",
    "Let's se the effect of using different spatial sampling and intensity leves quantiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "#Load an image \n",
    "I = cv2.imread(intro_images_path +\"bridge.jpg\", 1)\n",
    "if I is None:\n",
    "    raise Exception(\"File not found!\")\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "#subsampling of the original image and visualization at the relative scale\n",
    "Int_mostraxe = 2\n",
    "I2 = I[::Int_mostraxe,::Int_mostraxe,:]\n",
    "I3 = I2[::Int_mostraxe,::Int_mostraxe,:]\n",
    "plt.figure(figsize=[10,10]);plt.imshow(I);plt.title(\"Original\");plt.show()\n",
    "plt.figure(figsize=[5,5]);plt.imshow(I2);plt.title(\"Subsampled once\"); plt.show()\n",
    "plt.figure(figsize=[2.5,2.5]);plt.imshow(I3);plt.title(\"Subsampled twice\");plt.show()\n",
    "\n",
    "print('Dimensions de I1 = {}, I2 = {} e I3 = {}'.format(I.shape, I2.shape, I3.shape))\n",
    "\n",
    "#Visualization at the same scale\n",
    "plt.figure(figsize=[10,10]);plt.imshow(I);plt.title(\"Original\");plt.show()\n",
    "plt.figure(figsize=[10,10]);plt.imshow(I2);plt.title(\"Subsampled once\"); plt.show()\n",
    "plt.figure(figsize=[10,10]);plt.imshow(I3);plt.title(\"Subsampled twice\");plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "#Load an image as gray-level\n",
    "I0 = cv2.imread(intro_images_path +\"eiffel.jpg\", 0)\n",
    "if I is None:\n",
    "    raise Exception(\"File not found!\")\n",
    "\n",
    "I1 = cv2.resize(I0, fx = 0.5, fy = 0.5, dsize = None) # Resize image\n",
    "height = I1.shape[0] #shape[0] The first dimension of the image , Height\n",
    "width = I1.shape[1] #shape[1] The second dimension of the image , Width\n",
    "print('I1.shape.{}\\n'.format(width, height))\n",
    "plt.figure(figsize=[10,10]);plt.imshow(I1);plt.title(\"Original\");plt.show()\n",
    "# Create a matrix of the same size as the original image\n",
    "I2 = np.zeros((width, height), np.uint(8))\n",
    "I3 = np.zeros((width, height), np.uint(8))\n",
    "I4 = np.zeros((width, height), np.uint(8))\n",
    "I5 = np.zeros((width, height), np.uint(8))\n",
    "I6 = np.zeros((width, height), np.uint(8))\n",
    "# Operate on the values of the original image matrix\n",
    "I2 = np.uint8(I1/4) * 4\n",
    "#I3 = np.uint8(I1/8) * 8\n",
    "I4 = np.uint8(I1/16) * 16\n",
    "#I5 = np.uint8(I1/32) * 32\n",
    "I6 = np.uint8(I1/64) * 64\n",
    "I7 = np.uint8(I1/128) * 128\n",
    "\n",
    "# Display the resulting image\n",
    "title = ['64 bits', '16', '4', '2'] # Subgraph title\n",
    "img = [I2,I4,I6,I7]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=[15,15])\n",
    "    plt.subplot(2, 2, i + 1) #python List from 0 Start counting , So here i+1\n",
    "    plt.imshow(img[i], 'gray')\n",
    "    plt.title(title[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dkfPxUdOWvg"
   },
   "source": [
    "## Exercise Histogram Calculation in OpenCV\n",
    "\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.html#histograms-getting-started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_94is2HhOeYj"
   },
   "source": [
    "OpenCV offers cv2.calcHist() function to find the histogram. Let’s familiarize with the function and its parameters :\n",
    "cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "* images : it is the source image of type uint8 or float32. it should be given in square brackets, ie, “[img]”.\n",
    "* channels : it is also given in square brackets. It the index of channel for which we calculate histogram. For example, if input is grayscale image, its value is [0]. For color image, you can pass [0],[1] or [2] to calculate histogram of blue, green or red channel respectively.\n",
    "* mask : mask image. To find histogram of full image, it is given as “None”. But if you want to find histogram of particular region of image, you have to create a mask image for that and give it as mask. \n",
    "* histSize : this represents our BIN count. Need to be given in square brackets. For full scale, we pass [256].\n",
    "ranges : this is our RANGE. Normally, it is [0,256].\n",
    "\n",
    "So let us start with a sample image. Simply load the image in grayscale mode and find its full histogram.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1610379232670,
     "user": {
      "displayName": "Xosé M. Pardo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDK9_rXK-VnAMPThurPFbjh3ermYOtwwiKrrsh-w=s64",
      "userId": "09967233662722245852"
     },
     "user_tz": -60
    },
    "id": "hDX58FBwO9C-",
    "outputId": "f251a52b-6947-41e5-cbd0-66e425cd1985"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "img = cv2.imread(intro_images_path+'pazo.jpg',0)\n",
    "plt.title(\"matplotlib\")\n",
    "plt.hist(img.ravel(),256,[0,256]); plt.show()\n",
    "\n",
    " \n",
    "hist_item = cv2.calcHist([img],[0],None,[256],[0,256]) \n",
    "hist_norm=hist_item/img.size\n",
    "plt.plot(hist_norm)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim([0,256])\n",
    "plt.title(\"opencv\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BX_RtBdPY5k"
   },
   "source": [
    "hist is a 256x1 array, each value corresponds to the number of pixels in that image with its corresponding pixel value.\n",
    "\n",
    "A mask (white rectangle) can be created this way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1610388464074,
     "user": {
      "displayName": "Xosé M. Pardo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDK9_rXK-VnAMPThurPFbjh3ermYOtwwiKrrsh-w=s64",
      "userId": "09967233662722245852"
     },
     "user_tz": -60
    },
    "id": "X5kv-Jk7Pbdm",
    "outputId": "a775065a-e5e1-4116-f97e-faa0c90b437e"
   },
   "outputs": [],
   "source": [
    "# Create the basic black image \n",
    "mask = np.zeros(img.shape, dtype = \"uint8\")\n",
    "\n",
    "# Draw a white, filled rectangle on the mask image\n",
    "x=int(0.25*img.shape[0])\n",
    "y=int(0.25*img.shape[1])\n",
    "h= int(0.35*img.shape[0])\n",
    "w=int(0.15*img.shape[1])\n",
    "\n",
    "#-1 for a filled rectangle\n",
    "#cv2.rectangle(mask, (x,y), (x+h, y+w), (255, 255, 255), -1)\n",
    "mask[x:x+h,y:y+w]=255\n",
    "\n",
    "# Display constructed mask\n",
    "#cv2.namedWindow(\"Mask\", cv2.WINDOW_NORMAL)\n",
    "#cv2.imshow(\"Mask\", mask)\n",
    "#cv2.waitKey(0)\n",
    "plt.imshow(mask, cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9NGussaw-nl"
   },
   "source": [
    "***Histogram of a specific image region***\n",
    "\n",
    "Find the histogram for some specific image regions using masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 1569,
     "status": "ok",
     "timestamp": 1610385603909,
     "user": {
      "displayName": "Xosé M. Pardo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDK9_rXK-VnAMPThurPFbjh3ermYOtwwiKrrsh-w=s64",
      "userId": "09967233662722245852"
     },
     "user_tz": -60
    },
    "id": "b2XLQ1EY-Dbq",
    "outputId": "28a6004b-1ebd-4ac3-976d-f75289c1503d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(intro_images_path+'pazo.jpg',0)\n",
    "# create a mask\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "mask[100:300, 100:400] = 255\n",
    "masked_img =cv2.bitwise_and(img,img,mask = mask)\n",
    "# Calculate histogram with mask and without mask\n",
    "# Check third argument for mask\n",
    "\n",
    "hist_mask = cv2.calcHist([img],[0],mask,[256],[0,256])\n",
    "hist_full = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "\n",
    "plt.subplot(221), plt.imshow(img, 'gray'),plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(222), plt.imshow(mask,'gray'),plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(223), plt.imshow(masked_img, 'gray'),plt.xticks([]), plt.yticks([])\n",
    "hist_full_norm=hist_full/img.size\n",
    "hist_mask_norm=hist_mask/(200*300)\n",
    "plt.subplot(224), plt.plot(hist_full_norm), plt.plot(hist_mask_norm)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim([0,256])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1_Intro_CV1.ipynb",
   "provenance": [
    {
     "file_id": "1R5Atiwr1-7ZQ5KznAFTKBHxzmmuM3d4w",
     "timestamp": 1564409613050
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
